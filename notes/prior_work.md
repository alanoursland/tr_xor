## Prior Work

The quest to understand the internal mechanisms of deep neural networks has spurred a vast body of research, exploring their learning dynamics, representation geometry, and generalization capabilities. The proposed prototype surface theory contributes to this endeavor by positing that neural networks, even standard architectures, fundamentally learn prototype surfaces defining class-characteristic regions, with classification occurring via proximity to these surfaces. This perspective builds upon, and also offers a novel interpretation of, several key areas in existing literature.

### Foundations in Prototype Theory and Distance Learning

The conceptual roots of viewing classification in terms of prototypes trace back to cognitive psychology, where prototype theory (e.g., Nosofsky et al., 2018) explains human categorization based on similarity to a central prototype or exemplar. This notion has been computationally formalized in various ways. Modern efforts, such as human-level concept learning through probabilistic program induction (Lake et al., 2015), also demonstrate systems that learn concepts resembling prototype-based structures.

Directly implementing prototype-based mechanisms in neural networks has proven effective, particularly in few-shot learning and open-set recognition. Prototypical Networks, as surveyed by Jaiswal et al. (2024), explicitly compute class prototypes (often mean embeddings of support set examples) and classify query points based on distance to these prototypes. Specific architectures like Convolutional Prototype Networks (Yang et al., 2018; Yang et al., 2021) and Relational Prototypical Networks (Huang et al., 2020) demonstrate the utility of learned prototypes for tasks including robust classification, open-set recognition, and temporal action localization. Self-Organizing Maps (SOMs), as revisited by Chen et al. (2021), also learn a discretized mapping to a prototype-based topological structure. While these approaches explicitly design networks around prototypes, the prototype surface theory suggests that standard feedforward networks utilizing linear layers and ReLU activations implicitly learn to demarcate prototype regions through the geometry of their learned parameters. In contrast, absolute-value activations label only the boundary itself as the prototype, with output magnitude furnishing a learned distance metric.

This emphasis on proximity aligns strongly with the field of distance and similarity learning. Deep metric learning, surveyed by Kaya & Bilge (2019) and critically examined by Musgrave et al. (2020) and Roth et al. (2022), aims to learn embedding spaces where distances directly correspond to semantic similarity. Foundational techniques like triplet networks (Hoffer & Ailon, 2015; Xuan et al., 2020) and FaceNet's use of triplet loss (Schroff et al., 2015) explicitly optimize for this property. More recent works like ArcFace (Deng et al., 2022) and CosFace (Wang et al., 2018) introduce angular margin losses to further enhance discriminability by compacting intra-class variations and separating inter-class distributions, effectively shaping more prototypical clusters. The proposed theory posits that such proximity-based classification is not just a result of specialized losses but an inherent outcome of how standard networks process information via learned surfaces. Pitis et al. (2020) also explored inductive biases for distances, specifically enforcing the triangle inequality, which complements the geometric underpinnings of the prototype surface theory.

### Geometric Perspectives on Neural Network Representations

A significant body of work investigates the geometric properties of learned representations and decision processes in neural networks, providing fertile ground for the prototype surface theory.

**Understanding Learned Representations and Their Structure:** Research on the similarity of neural network representations (Kornblith et al., 2019) and the alignment of representations across different networks or training stages (van Rossem & Saxe, 2024; Brown et al., 2023) seeks to uncover the underlying structure learned by these models. A key phenomenon observed is Neural Collapse (Papyan et al., 2020; Andriopoulos et al., 2024), where, in the terminal phase of training, last-layer features and classifiers converge to highly symmetric and structured geometric configurations. This emergent simplicity, with class features collapsing towards their means which themselves form vertices of a simplex, can be seen as an extreme form of prototypicality. The prototype surface theory would interpret these collapsed feature locations as key points on or within the broader learned prototype surfaces that define each class region.

**Manifold Learning and Intrinsic Dimensionality:** The hypothesis that high-dimensional data often lies on lower-dimensional manifolds (Pope et al., 2021; Ansuini et al., 2019) is central. If class data resides on such manifolds, it is natural for a network to learn representations or surfaces that capture these intrinsic structures. The prototype surface theory aligns with this, proposing that networks learn surfaces characteristic of where each class naturally resides. Understanding the role of intrinsic dimension in deep learning (He & Yu, 2023) further informs how such surfaces might be efficiently learned.

**Decision Boundaries and Network Geometry:** Traditional analysis often focuses on the decision boundaries formed by neural networks (Antognini & Faltings, 2021; Vardanega et al., 2022 survey). The prototype surface theory reframes this by suggesting that the primary objects learned are prototype surfaces defining class regions, with decision boundaries emerging from the interplay of these regions. The theory provides a specific geometric interpretation where the hyperplane $Wx+b=0$ acts as a boundary for a prototype region, and the ReLU activation function $ReLU(Wx+b)$ extends this region to an entire half-space where the neuron's output is zero, signifying inclusion. Stephenson et al. (2021) studying loss surface geometry in overparameterized models also contributes to understanding the geometric underpinnings of network behavior. The work of Montúfar et al. (2014) on the number of linear regions created by ReLU activations, further explored by Serra et al. (2018) and Hanin & Rolnick (2019), quantifies the functional complexity that underpins the ability to form these intricate prototype surfaces. Topological Data Analysis (TDA) approaches (Carlsson, 2009; Rieck & Leitte, 2019; Naitzat et al., 2020) offer tools to probe the topological structure of these learned representations and surfaces.

**Specialized Architectures with Geometric Priors:** Capsule Networks (Sabour et al., 2017; Wang & Liu, 2021 survey; Mazzia et al., 2021) explicitly incorporate geometric relationships and hierarchies, resonating with the idea of hierarchically constructed prototype surfaces that can capture part-whole relationships and equivariant properties.

### Interpretability, Generalization, and Broader Connections

The way networks generalize, especially the findings in Zhang et al. (2017) that deep networks can fit random labels yet still generalize on real data, challenges simple notions of decision boundary complexity. The prototype surface theory, by positing that networks learn extended prototype regions (half-spaces), may offer new perspectives on generalization and the capacity of networks. This view might also shed light on why techniques like data augmentation are effective, as they might help solidify the "shape" and extent of these prototype surfaces. The connection between overparameterized NNs and kernel machines (Belkin et al., 2019; Liang et al., 2020) also provides a related lens on generalization through non-local functions.

The concept of prototype surfaces also has strong implications for Explainable AI (XAI). Methods that provide prototype-based or case-based explanations, such as identifying influential training instances (Chen et al., 2019 - "This looks like that") or using concept activation vectors (Kim et al., 2018; Ghorbani et al., 2019), align well with a model that inherently learns prototypical representations. If networks indeed learn regions corresponding to prototypes, then explanations based on similarity to learned prototypes are a natural fit.

Finally, the ideas of disentangled representations (Bengio et al., 2013; Higgins et al., 2017; Locatello et al., 2019) and invariant feature learning (Arjovsky et al., 2019; Goyal et al., 2022), often linked to causality (Schölkopf, 2022), aim to learn features that capture fundamental, stable aspects of the data. Prototype surfaces, if they capture the "characteristic structure" of a class, could be composed of such invariant or disentangled features.

The prototype surface theory thus offers a cohesive geometric framework that reinterprets the function of standard neural network components. It seeks to explain how networks learn by defining regions of acceptance around prototypical forms, rather than solely by partitioning space with boundaries. This perspective aims to provide a richer understanding of network behavior, representation, and generalization.